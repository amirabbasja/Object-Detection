{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 13:49:40.311055: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-24 13:49:40.325531: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-24 13:49:40.329748: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-24 13:49:40.339964: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-24 13:49:41.138988: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721816382.105444   45109 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721816382.147903   45109 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721816382.148088   45109 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import sys, os\n",
    "from keras.regularizers import l2\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "here = os.path.dirname(\".\")\n",
    "sys.path.append(os.path.join(here, '..'))\n",
    "\n",
    "from dataHandler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv1_LastLayer_Reshape(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Defines a costume layer for reshaping the last layer to YOLOv1 compatible layer.\n",
    "    Note, No build function is needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, targetShape):\n",
    "        \"\"\"\n",
    "        Initializes the layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.targetShape = tuple(targetShape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Helps in serializing the layer data\n",
    "        \"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\"target_shape\": self.targetShape})\n",
    "        return config\n",
    "\n",
    "    def call(self, layerInput):\n",
    "        \"\"\"\n",
    "        Forward computations. We take the first Sx * Sy * C indexes of each the input \n",
    "        vector to resemble the class probabilities of each grid cell. The rest of the \n",
    "        Sx * Sy * B indexes resemble the confidence scores of each grid cell And the \n",
    "        rest resemble the bounding box parameters <boxCenterX, boxCenterY, width, height>  \n",
    "\n",
    "        Args:\n",
    "            layerInput: tensor: The output from a dense (fully connected) layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        Sx, Sy = self.targetShape[0], self.targetShape[1] # Number of parts that each axis is divided to\n",
    "        C = 1 # Number of classes\n",
    "        B = 2 # Number of predicted bounding boxes per grid cell\n",
    "\n",
    "\n",
    "        # Get the batch size\n",
    "        batchSize = tf.keras.backend.shape(layerInput)[0]\n",
    "\n",
    "        # Class probabilities\n",
    "        classProbs = tf.keras.backend.reshape(layerInput[:,:Sx*Sy*C], (batchSize,) + (Sx,Sy,C))\n",
    "        classProbs = tf.keras.backend.softmax(classProbs) # Run a softmax to choose the right class with highest prob\n",
    "\n",
    "        # Confidence scores\n",
    "        confScores = tf.keras.backend.reshape(layerInput[:,Sx*Sy*C:Sx*Sy*(C+B)], (batchSize,) + (Sx,Sy,B))\n",
    "        confScores = tf.keras.backend.sigmoid(confScores) # Confidence scores should be between 0 and 1\n",
    "\n",
    "        # Bounding boxes\n",
    "        bBox = tf.keras.backend.reshape(layerInput[:,Sx*Sy*(C+B):], (batchSize,) + (Sx,Sy,B*4))\n",
    "        bBox = tf.keras.backend.sigmoid(bBox) # All of the bounding box parameters are relative (Between 0 and 1)\n",
    "\n",
    "\n",
    "        return tf.keras.backend.concatenate([classProbs, confScores, bBox])\n",
    "\n",
    "# # # Define a simple model using the custom reshaper layer to test it\n",
    "# # input = tf.keras.layers.Input(shape=(539,))\n",
    "# # x = YOLOv1_LastLayer_Reshape((7,7,11))(input)\n",
    "# # model = tf.keras.Model(inputs = input, outputs = x, name = \"dummy\")\n",
    "# # model.compile(optimizer='adam',  loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# # xTest = np.random.randint(10, size = (1,539))\n",
    "# # pred = model.predict(xTest)\n",
    "# # print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1721816382.167745   45109 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721816382.168048   45109 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721816382.168211   45109 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721816382.241892   45109 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721816382.242073   45109 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1721816382.242205   45109 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-24 13:49:42.242299: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4807 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def iouUtils(boxParams, gridRatio = tf.constant(7, tf.float32)):\n",
    "    \"\"\"\n",
    "    Given bounding box centers and its width and height, calculates top-left and bottom-right coordinates of the box.\n",
    "    Note that calculations in this function are done with teh assumption of w and h being a float number, between 0 and 1\n",
    "    with respect to the entire image's size. However, x and y of the bounding box's center are assumed to be a float \n",
    "    between 0 and 1, with respect to the upper-left point of the grid cell.\n",
    "\n",
    "    Args:\n",
    "        boxParams: tf.Tensor: A tensor with following information (Box center X, Box center Y, Box width, Box height) for all\n",
    "            boxes in a tensor.\n",
    "        gridRatio: int: The number of evenly distributed grid cells in each image axis. Use 7 for YOLOv1.\n",
    "    \n",
    "    Returns:\n",
    "        Two tensors, one indicating top-left pint of the bBox and, the other one denoting bottom-right edge.\n",
    "    \"\"\"\n",
    "    boxXY = boxParams[...,0:2]\n",
    "    halfWH = tf.divide(boxParams[...,2:], tf.constant([2.]))\n",
    "\n",
    "    # Top-left (X, Y) and bottom-right (X, Y)\n",
    "    return tf.subtract(boxXY, halfWH * gridRatio), tf.add(boxXY, halfWH * gridRatio)\n",
    "\n",
    "def calcIOU(predict_topLeft, predict_bottomRight, truth_topLeft, truth_bottomRight):\n",
    "    \"\"\"\n",
    "    Calculates intersection over union for two bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        predict_topLeft, predict_bottomRight: tf.Tensor: Top-left and bottom-right coordinates of the predicted box, acquired \n",
    "            by iouUtils.\n",
    "        truth_topLeft, truth_bottomRight: tf.Tensor: Top-left and bottom-right coordinates of the ground truth box, acquired \n",
    "            by iouUtils.\n",
    "    \n",
    "    Returns:\n",
    "        Intersection over union of two boxes\n",
    "    \"\"\"\n",
    "\n",
    "    intersectEdgeLeft = tf.maximum(predict_topLeft, truth_topLeft)\n",
    "    intersectEdgeRight = tf.minimum(predict_bottomRight, truth_bottomRight)\n",
    "    \n",
    "    intersectWH = tf.abs(tf.subtract(intersectEdgeLeft, intersectEdgeRight))\n",
    "    intersectArea = tf.reduce_prod(intersectWH, axis = -1)\n",
    "\n",
    "    # Get area of predicted and ground truth bounding boxes\n",
    "    predArea = tf.reduce_prod(tf.abs(tf.subtract(predict_topLeft, predict_bottomRight)), axis = -1)\n",
    "    truthArea = tf.reduce_prod(tf.abs(tf.subtract(truth_topLeft, truth_bottomRight)), axis = -1)\n",
    "\n",
    "    \n",
    "    # Return IOU\n",
    "    return tf.divide(intersectArea, predArea + truthArea - intersectArea)\n",
    "\n",
    "# #  Testing IOU code\n",
    "# predict = tf.random.uniform((3,4))\n",
    "# truth = tf.random.uniform((3,4))\n",
    "# p1, p2 = iouUtils(predict)\n",
    "# t1, t2 = iouUtils(truth)\n",
    "# print(calcIOU(p1, p2, t1, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv1 Loss\n",
    "class YOLOv1_Loss(tf.keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    Defines the custom loss function that is used for YOLOv1 network.\n",
    "    The loss is calculated in 3 parts:\n",
    "    1. Localization Loss\n",
    "    2. Confidence Loss\n",
    "    3. Classification Loss\n",
    "\n",
    "    Note: In this method's documentation, \"ground truth\" and \"target\" are used interchangeably \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Sx = 7, Sy = 7, B_target = 1, B_pred = 2, C = 1):\n",
    "        \"\"\"\n",
    "        Initializes the loss function. \n",
    "\n",
    "        Args:\n",
    "            Sx: int: Number of grid cells on x axis\n",
    "            Sy: int: Number of grid cells on y axis \n",
    "            B_target: int: Number of bounding boxes in the ground truth data\n",
    "            B_pred: int: Number of bounding boxes in prediction\n",
    "            C: int: Number of the classes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Define YOLOv1 parameters\n",
    "        self.Sx = Sx\n",
    "        self.Sy = Sy\n",
    "        self.B_target = B_target # Ground truth grid cells only have one bounding box \n",
    "        self.B_pred = B_pred\n",
    "        self.C = C\n",
    "\n",
    "    def call(self, yTrue, yPred):\n",
    "\n",
    "        return 1\n",
    "        \n",
    "def testLoss(yTrue, yPred):\n",
    "    \"\"\"\n",
    "    Runs in the even of loss function calculations\n",
    "    \n",
    "    Args:\n",
    "        yTrue, yPred: tf.Tensor: The ground truth value and the predicted value, respectively\n",
    "\n",
    "    Returns:\n",
    "        The calculated loss.\n",
    "    \"\"\"\n",
    "    lambdaNoObj = tf.constant(.5)\n",
    "    lambdaCoord = tf.constant(5.)\n",
    "\n",
    "    # Split the predictions and ground truth vectors to coordinates, confidence and class matrices\n",
    "    # 1. Ground truth \n",
    "    idx1, idx2 = 1, 1 + 1\n",
    "    targetClass = yTrue[...,:idx1]\n",
    "    targetConf = yTrue[...,idx1:idx2]\n",
    "    targetCoords = yTrue[...,idx2:]\n",
    "\n",
    "    # 2. Prediction\n",
    "    idx1, idx2 = 1, 1 + 2\n",
    "    predClass = yPred[...,:idx1]\n",
    "    predConf = yPred[...,idx1:idx2]\n",
    "    predCoords = yPred[...,idx2:]\n",
    "\n",
    "    # Get the best bounding boxes by calculating the IOUs\n",
    "    # Note: To to do this process for the confidence scores as well, we concat each box's confidence\n",
    "    # score to its bounding box coordinates and analyze them as a whole.\n",
    "    predBox1 = tf.concat([tf.expand_dims(predConf[...,0],-1),predCoords[...,:4]], axis = -1)\n",
    "    predBox2 = tf.concat([tf.expand_dims(predConf[...,1],-1),predCoords[...,4:]], axis = -1)\n",
    "\n",
    "    # Get the corners of bounding boxes to calculate IOUs\n",
    "    # Note, iouUtils is not coded to accept confidence scores. So we only pass the coordinates into \n",
    "    # it. \n",
    "    p1_left, p1_right = iouUtils(predBox1[...,1:]) \n",
    "    p2_left, p2_right = iouUtils(predBox2[...,1:])\n",
    "    t_left, t_right = iouUtils(targetCoords) \n",
    "\n",
    "    # Calculate IOUs for first and second predicted bounding box\n",
    "    p1_IOU = calcIOU(p1_left, p1_right, t_left, t_right)\n",
    "    p2_IOU = calcIOU(p2_left, p2_right, t_left, t_right)\n",
    "\n",
    "    # Get the cells that have objects\n",
    "    maskObj = tf.cast(0 < targetConf, tf.float32)\n",
    "    maskNoObj = tf.cast(0 == targetConf, tf.float32)\n",
    "    \n",
    "    mask_p1Bigger = tf.expand_dims(tf.cast(p2_IOU < p1_IOU, tf.float32),-1)\n",
    "    mask_p2Bigger = tf.expand_dims(tf.cast(p1_IOU <= p2_IOU, tf.float32),-1)\n",
    "\n",
    "    # Getting the responsible bounding box for loss calculation. Output is of shape [...,5]\n",
    "    # And the first element is the confidence score of that box.\n",
    "    respBox = maskObj*(mask_p1Bigger * predBox1 + mask_p2Bigger * predBox2)\n",
    "\n",
    "    # Calculating the losses\n",
    "    # 1. Classification loss\n",
    "    classificationLoss =  tf.math.reduce_sum(tf.math.square(maskObj * tf.subtract(targetClass, predClass)))\n",
    "\n",
    "    # 2. Confidence loss\n",
    "    # Bear in mind, for the boxes with no objects, we account for the confidence loss as well. \n",
    "    # To penalize the network for high confidence scores of the cells containing no objects. The \n",
    "    # cells that have no objects, have a confidence score of 0 in the target ground truth matrix.\n",
    "    # Thus, the loss is calculated as follows: SUM_All_Cells_No_OBJ((C1-0)^2 + (C2-0)^2)\n",
    "    confidenceLossObj = tf.math.reduce_sum(tf.math.square(maskObj * tf.subtract(targetConf, tf.expand_dims(respBox[...,0],-1))))\n",
    "    confidenceLossNoObj =  lambdaNoObj * tf.reduce_sum(maskNoObj * tf.reduce_sum(tf.square(predConf), axis = -1, keepdims = True))\n",
    "    \n",
    "    # 3. Localization loss\n",
    "    # Bear in mind that respBox is of the shape (...,5) and targetCoords dimension is (...,4) \n",
    "    xyLoss = (tf.reduce_sum(tf.square(tf.subtract(respBox[...,1:3], targetCoords[...,0:2])),-1,True))\n",
    "    whLoss = (tf.reduce_sum(tf.square(tf.subtract(tf.sqrt(respBox[...,1:3]), tf.sqrt(targetCoords[...,0:2]))),-1,True))\n",
    "    localizationLoss = lambdaCoord * (xyLoss + whLoss) \n",
    "\n",
    "    # Sum all the tree types of the errors\n",
    "    return classificationLoss + confidenceLossNoObj + confidenceLossObj + localizationLoss\n",
    "\n",
    "\n",
    "# # Define a simple model using the custom reshaper layer to test it\n",
    "# input = tf.keras.layers.Input(shape=(539,))\n",
    "# x = YOLOv1_LastLayer_Reshape((7,7,11))(input)\n",
    "# model = tf.keras.Model(inputs = input, outputs = x, name = \"dummy\")\n",
    "# model.compile(optimizer='adam',  loss=testLoss, metrics=['accuracy'])\n",
    "\n",
    "# xTest = np.random.randint(10, size = (1,539))\n",
    "# pred = model.predict(xTest)\n",
    "# # model.evaluate(xTest,np.expand_dims(yTruth, 0),)\n",
    "# model.fit(xTest, np.expand_dims(yTruth, 0), epochs = 1)\n",
    "# # metrics = model.evaluate(xTest)\n",
    "# # print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv1 structure\n",
    "YOLOv1_inputShape = (448,448,3) # Shape of the input image \n",
    "classNo = 1 # Number of classes we are trying to detect\n",
    "input = tf.keras.layers.Input(shape=YOLOv1_inputShape)\n",
    "leakyReLu = tf.keras.layers.LeakyReLU(negative_slope = .1)\n",
    "\n",
    "\n",
    "# The backbone, Acts ads a feature extractor\n",
    "# L1\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size=7, strides = 2, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(input)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L2\n",
    "x = tf.keras.layers.Conv2D(filters = 192, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L3\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L4\n",
    "for _ in range(4):\n",
    "    x = tf.keras.layers.Conv2D(filters = 256, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "    x = tf.keras.layers.Conv2D(filters = 512, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L5\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 2, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "\n",
    "# L6\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "\n",
    "# Neck\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(4096)(x)\n",
    "x = tf.keras.layers.Dense(7*7*(5*2+classNo), activation=\"sigmoid\")(x)\n",
    "x = tf.keras.layers.Dropout(.5)(x) # Dropout layer for avoiding overfitting\n",
    "x = YOLOv1_LastLayer_Reshape((7,7,5*2+classNo))(x)\n",
    "model = tf.keras.Model(inputs = input, outputs = x, name = \"YOLOv1\")\n",
    "\n",
    "model.compile(loss = testLoss ,optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrScheduler(epoch, schedule, currentLR):\n",
    "    \"\"\"\n",
    "    Returns a learning rate value with respect to epoch number.\n",
    "\n",
    "    Args: \n",
    "        epoch: int: the current epoch number.\n",
    "        schedule: list: A list of tuples of epoch number and its respective learning rate value. \n",
    "            If the epoch number of the fitting process doesn't reach the specified epoch number,\n",
    "            the learning rate will remail unchanged. The entries have to be in order of epoch \n",
    "            numbers.\n",
    "        currentLR: float: The learning rate of the model before starting the most recent epoch.\n",
    "\n",
    "    Returns: float: learning rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    newLR = currentLR\n",
    "\n",
    "    for entry in schedule:\n",
    "        if entry[0] == epoch:\n",
    "            newLR = float(entry[1])\n",
    "    \n",
    "    return newLR\n",
    "\n",
    "class customLearningRate(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Sets the learning rate of the fitting process with respect to the epoch number.\n",
    "\n",
    "    Args:\n",
    "        schedule: method: Using the epoch number, returns the suitable learning rate\n",
    "        LR_schedule: list: A list of tuples of epoch number and its respective learning rate value. \n",
    "            If the epoch number of the fitting process doesn't reach the specified epoch number,\n",
    "            the learning rate will remail unchanged. The entries have to be in order of epoch \n",
    "            numbers.\n",
    "    \"\"\"\n",
    "    def __init__(self, scheduleFCN, LR_schedule):\n",
    "        \"\"\"\n",
    "        Initialized the class\n",
    "\n",
    "        Args: \n",
    "            scheduleFCN: method: A method that returns new learning rate\n",
    "            LR_schedule: list: \n",
    "        \"\"\"\n",
    "        super(customLearningRate, self).__init__()\n",
    "        self.LR_schedule = LR_schedule\n",
    "        self.scheduleFCN = scheduleFCN\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Runs on the epoch start.\n",
    "\n",
    "        Args:\n",
    "            epoch: int: The current epoch number.\n",
    "        \"\"\"\n",
    "\n",
    "        # # Check to see of the model has defined a learning rate\n",
    "        # if hasattr(self.model.optimizer, \"lr\"):\n",
    "        #     raise Exception(\"custom learning rate generator: First define a learning rate for the model.\")\n",
    "        \n",
    "        # Get current learning rate\n",
    "        learningRate = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "\n",
    "        # Get the new learning rate\n",
    "        newLearningRate = self.scheduleFCN(epoch, self.LR_schedule, learningRate)\n",
    "\n",
    "        # Set the new learning rate as the model's learning rate\n",
    "        \n",
    "        self.model.optimizer.learning_rate.assign(newLearningRate)\n",
    "\n",
    "        # Notify the user\n",
    "        if learningRate != newLearningRate:\n",
    "            tf.print(f\"Updated the learning rate at epoch NO. {epoch}. New learning rate: {newLearningRate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "Updated the learning rate at epoch NO. 0. New learning rate: 0.01\n",
      "Epoch 1/135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abbas/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1721816388.695665   45174 service.cc:146] XLA service 0x75b3e000c660 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1721816388.695697   45174 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-07-24 13:49:48.928212: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-24 13:49:49.517602: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "2024-07-24 13:49:51.481901: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-24 13:49:51.481933: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-24 13:49:51.481944: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-24 13:49:51.557956: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-24 13:49:51.557989: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-24 13:49:51.558000: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 9.14GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-24 13:49:51.558011: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 17.10GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-24 13:49:51.611029: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-24 13:49:51.611063: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-24 13:49:51.611075: W external/local_tsl/tsl/framework/bfc_allocator.cc:291] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "E0000 00:00:1721816392.736764   45174 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "E0000 00:00:1721816392.877300   45174 gpu_timer.cc:183] Delay kernel timed out: measured time has sub-optimal accuracy. There may be a missing warmup execution, please investigate in Nsight Systems.\n",
      "2024-07-24 13:49:56.003626: W external/local_xla/xla/service/hlo_rematerialization.cc:3005] Can't reduce memory use below 1.56GiB (1672484982 bytes) by rematerialization; only reduced to 3.36GiB (3606565636 bytes), down from 3.87GiB (4160077193 bytes) originally\n",
      "2024-07-24 13:49:56.318366: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:762] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.3.107). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   1/1026\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:16:57\u001b[0m 15s/step - loss: 18.1710"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 13:49:58.036271: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_12', 20 bytes spill stores, 20 bytes spill loads\n",
      "\n",
      "I0000 00:00:1721816398.068843   45174 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 229/1026\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:10\u001b[0m 89ms/step - loss: nan"
     ]
    }
   ],
   "source": [
    "# See if the directory to save the checkpoints exists\n",
    "if not os.path.isdir(f\"{os.getcwd()}/model_data\"):\n",
    "    os.mkdir(f\"{os.getcwd()}/model_data\")\n",
    "\n",
    "# Instantiate the checkpoint object\n",
    "chkPoint = ModelCheckpoint(filepath='./model_data/model_{epoch:02d}-{val_loss:.2f}.keras',\n",
    "                                    save_best_only=True,\n",
    "                                    monitor='val_loss',\n",
    "                                    mode='min',\n",
    "                                    verbose=1\n",
    "                            )\n",
    "\n",
    "batch_size = 4\n",
    "LR_schedule = [\n",
    "    (0, 0.01),\n",
    "    (75, 0.001),\n",
    "    (105, 0.0001),\n",
    "]\n",
    "\n",
    "dfTrain = annotationsToDataframe(f\"../data/labels/train\", \"txt\")\n",
    "trainingBatchGenerator = dataGenerator_YOLOv1(f\"../data/images/train\", 1, (448,448), dfTrain, 1, True)\n",
    "\n",
    "dfTest = annotationsToDataframe(f\"../data/labels/test\", \"txt\")\n",
    "testingBatchGenerator = dataGenerator_YOLOv1(f\"../data/images/test\", 1, (448,448), dfTrain, 1, True)\n",
    "print(int(dfTrain.shape[0] // batch_size))\n",
    "\n",
    "model.fit(x=trainingBatchGenerator,\n",
    "        steps_per_epoch = int(dfTrain.shape[0] // batch_size),\n",
    "        epochs = 135,\n",
    "        verbose = 1,\n",
    "        validation_data = testingBatchGenerator,\n",
    "        validation_steps = int(len(dfTest) // batch_size),\n",
    "        callbacks = [\n",
    "            customLearningRate(lrScheduler, LR_schedule),\n",
    "            chkPoint,\n",
    "        ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
