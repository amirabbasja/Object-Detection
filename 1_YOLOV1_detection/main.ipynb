{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 19:31:56.513859: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-20 19:31:57.263342: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 19:31:58.351745: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-20 19:31:58.370925: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-20 19:31:58.371103: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import keras.backend as K\n",
    "import sys, os\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "here = os.path.dirname(\".\")\n",
    "sys.path.append(os.path.join(here, '..'))\n",
    "\n",
    "from dataHandler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv1_LastLayer_Reshape(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Defines a costume layer for reshaping the last layer to YOLOv1 compatible layer.\n",
    "    Note, No build function is needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, targetShape):\n",
    "        \"\"\"\n",
    "        Initializes the layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.targetShape = tuple(targetShape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Helps in serializing the layer data\n",
    "        \"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\"target_shape\": self.targetShape})\n",
    "        return config\n",
    "\n",
    "    def call(self, layerInput):\n",
    "        \"\"\"\n",
    "        Forward computations. We take the first Sx * Sy * C indexes of each the input \n",
    "        vector to resemble the class probabilities of each grid cell. The rest of the \n",
    "        Sx * Sy * B indexes resemble the confidence scores of each grid cell And the \n",
    "        rest resemble the bounding box parameters <boxCenterX, boxCenterY, width, height>  \n",
    "\n",
    "        Args:\n",
    "            layerInput: tensor: The output from a dense (fully connected) layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        Sx, Sy = self.targetShape[0], self.targetShape[1] # Number of parts that each axis is divided to\n",
    "        C = 1 # Number of classes\n",
    "        B = 2 # Number of predicted bounding boxes per grid cell\n",
    "\n",
    "\n",
    "        # Get the batch size\n",
    "        batchSize = tf.keras.backend.shape(layerInput)[0]\n",
    "\n",
    "        # Class probabilities\n",
    "        classProbs = tf.keras.backend.reshape(layerInput[:,:Sx*Sy*C], (batchSize,) + (Sx,Sy,C))\n",
    "        classProbs = tf.keras.backend.softmax(classProbs) # Run a softmax to choose the right class with highest prob\n",
    "\n",
    "        # Confidence scores\n",
    "        confScores = tf.keras.backend.reshape(layerInput[:,Sx*Sy*C:Sx*Sy*(C+B)], (batchSize,) + (Sx,Sy,B))\n",
    "        confScores = tf.keras.backend.sigmoid(confScores) # Confidence scores should be between 0 and 1\n",
    "\n",
    "        # Bounding boxes\n",
    "        bBox = tf.keras.backend.reshape(layerInput[:,Sx*Sy*(C+B):], (batchSize,) + (Sx,Sy,B*4))\n",
    "        bBox = tf.keras.backend.sigmoid(bBox) # All of the bounding box parameters are relative (Between 0 and 1)\n",
    "\n",
    "\n",
    "        return tf.keras.backend.concatenate([classProbs, confScores, bBox])\n",
    "\n",
    "# # # Define a simple model using the custom reshaper layer to test it\n",
    "# # input = tf.keras.layers.Input(shape=(539,))\n",
    "# # x = YOLOv1_LastLayer_Reshape((7,7,11))(input)\n",
    "# # model = tf.keras.Model(inputs = input, outputs = x, name = \"dummy\")\n",
    "# # model.compile(optimizer='adam',  loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# # xTest = np.random.randint(10, size = (1,539))\n",
    "# # pred = model.predict(xTest)\n",
    "# # print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 19:31:58.400751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-20 19:31:58.400971: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-20 19:31:58.401092: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-20 19:31:58.466511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-20 19:31:58.466703: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-20 19:31:58.466826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-20 19:31:58.466922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4807 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def iouUtils(boxParams, gridRatio = tf.constant(7, tf.float32)):\n",
    "    \"\"\"\n",
    "    Given bounding box centers and its width and height, calculates top-left and bottom-right coordinates of the box.\n",
    "    Note that calculations in this function are done with teh assumption of w and h being a float number, between 0 and 1\n",
    "    with respect to the entire image's size. However, x and y of the bounding box's center are assumed to be a float \n",
    "    between 0 and 1, with respect to the upper-left point of the grid cell.\n",
    "\n",
    "    Args:\n",
    "        boxParams: tf.Tensor: A tensor with following information (Box center X, Box center Y, Box width, Box height) for all\n",
    "            boxes in a tensor.\n",
    "        gridRatio: int: The number of evenly distributed grid cells in each image axis. Use 7 for YOLOv1.\n",
    "    \n",
    "    Returns:\n",
    "        Two tensors, one indicating top-left pint of the bBox and, the other one denoting bottom-right edge.\n",
    "    \"\"\"\n",
    "    boxXY = boxParams[...,0:2]\n",
    "    halfWH = tf.divide(boxParams[...,2:], tf.constant([2.]))\n",
    "\n",
    "    # Top-left (X, Y) and bottom-right (X, Y)\n",
    "    return tf.subtract(boxXY, halfWH * gridRatio), tf.add(boxXY, halfWH * gridRatio)\n",
    "\n",
    "def calcIOU(predict_topLeft, predict_bottomRight, truth_topLeft, truth_bottomRight):\n",
    "    \"\"\"\n",
    "    Calculates intersection over union for two bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        predict_topLeft, predict_bottomRight: tf.Tensor: Top-left and bottom-right coordinates of the predicted box, acquired \n",
    "            by iouUtils.\n",
    "        truth_topLeft, truth_bottomRight: tf.Tensor: Top-left and bottom-right coordinates of the ground truth box, acquired \n",
    "            by iouUtils.\n",
    "    \n",
    "    Returns:\n",
    "        Intersection over union of two boxes\n",
    "    \"\"\"\n",
    "\n",
    "    intersectEdgeLeft = tf.maximum(predict_topLeft, truth_topLeft)\n",
    "    intersectEdgeRight = tf.minimum(predict_bottomRight, truth_bottomRight)\n",
    "    \n",
    "    intersectWH = tf.abs(tf.subtract(intersectEdgeLeft, intersectEdgeRight))\n",
    "    intersectArea = tf.reduce_prod(intersectWH, axis = -1)\n",
    "\n",
    "    # Get area of predicted and ground truth bounding boxes\n",
    "    predArea = tf.reduce_prod(tf.abs(tf.subtract(predict_topLeft, predict_bottomRight)), axis = -1)\n",
    "    truthArea = tf.reduce_prod(tf.abs(tf.subtract(truth_topLeft, truth_bottomRight)), axis = -1)\n",
    "\n",
    "    \n",
    "    # Return IOU\n",
    "    return tf.divide(intersectArea, predArea + truthArea - intersectArea)\n",
    "\n",
    "# #  Testing IOU code\n",
    "# predict = tf.random.uniform((3,4))\n",
    "# truth = tf.random.uniform((3,4))\n",
    "# p1, p2 = iouUtils(predict)\n",
    "# t1, t2 = iouUtils(truth)\n",
    "# print(calcIOU(p1, p2, t1, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get test  ground truth vector\n",
    "df = generateGroundTruth_YOLOv1(\"../data/labels/train\", \"txt\", (7,7,1,1))\n",
    "yTruth = df.at[\"04c8acd4a5be79bc\", \"vector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv1 Loss\n",
    "class YOLOv1_Loss(tf.keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    Defines the custom loss function that is used for YOLOv1 network.\n",
    "    The loss is calculated in 3 parts:\n",
    "    1. Localization Loss\n",
    "    2. Confidence Loss\n",
    "    3. Classification Loss\n",
    "\n",
    "    Note: In this method's documentation, \"ground truth\" and \"target\" are used interchangeably \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Sx = 7, Sy = 7, B_target = 1, B_pred = 2, C = 1):\n",
    "        \"\"\"\n",
    "        Initializes the loss function. \n",
    "\n",
    "        Args:\n",
    "            Sx: int: Number of grid cells on x axis\n",
    "            Sy: int: Number of grid cells on y axis \n",
    "            B_target: int: Number of bounding boxes in the ground truth data\n",
    "            B_pred: int: Number of bounding boxes in prediction\n",
    "            C: int: Number of the classes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Define YOLOv1 parameters\n",
    "        self.Sx = Sx\n",
    "        self.Sy = Sy\n",
    "        self.B_target = B_target # Ground truth grid cells only have one bounding box \n",
    "        self.B_pred = B_pred\n",
    "        self.C = C\n",
    "\n",
    "    def call(self, yTrue, yPred):\n",
    "\n",
    "        return 1\n",
    "        \n",
    "def testLoss(yTrue, yPred):\n",
    "    \"\"\"\n",
    "    Runs in the even of loss function calculations\n",
    "    \n",
    "    Args:\n",
    "        yTrue, yPred: tf.Tensor: The ground truth value and the predicted value, respectively\n",
    "\n",
    "    Returns:\n",
    "        The calculated loss.\n",
    "    \"\"\"\n",
    "    lambdaNoObj = tf.constant(.5)\n",
    "    lambdaCoord = tf.constant(5.)\n",
    "\n",
    "    # Split the predictions and ground truth vectors to coordinates, confidence and class matrices\n",
    "    # 1. Ground truth \n",
    "    idx1, idx2 = 1, 1 + 1\n",
    "    targetClass = yTrue[...,:idx1]\n",
    "    targetConf = yTrue[...,idx1:idx2]\n",
    "    targetCoords = yTrue[...,idx2:]\n",
    "\n",
    "    # 2. Prediction\n",
    "    idx1, idx2 = 1, 1 + 2\n",
    "    predClass = yPred[...,:idx1]\n",
    "    predConf = yPred[...,idx1:idx2]\n",
    "    predCoords = yPred[...,idx2:]\n",
    "\n",
    "    # Get the best bounding boxes by calculating the IOUs\n",
    "    # Note: To to do this process for the confidence scores as well, we concat each box's confidence\n",
    "    # score to its bounding box coordinates and analyze them as a whole.\n",
    "    predBox1 = tf.concat([tf.expand_dims(predConf[...,0],-1),predCoords[...,:4]], axis = -1)\n",
    "    predBox2 = tf.concat([tf.expand_dims(predConf[...,1],-1),predCoords[...,4:]], axis = -1)\n",
    "\n",
    "    # Get the corners of bounding boxes to calculate IOUs\n",
    "    # Note, iouUtils is not coded to accept confidence scores. So we only pass the coordinates into \n",
    "    # it. \n",
    "    p1_left, p1_right = iouUtils(predBox1[...,1:]) \n",
    "    p2_left, p2_right = iouUtils(predBox2[...,1:])\n",
    "    t_left, t_right = iouUtils(targetCoords) \n",
    "\n",
    "    # Calculate IOUs for first and second predicted bounding box\n",
    "    p1_IOU = calcIOU(p1_left, p1_right, t_left, t_right)\n",
    "    p2_IOU = calcIOU(p2_left, p2_right, t_left, t_right)\n",
    "\n",
    "    # Get the cells that have objects\n",
    "    maskObj = tf.cast(0 < targetConf, tf.float32)\n",
    "    maskNoObj = tf.cast(0 == targetConf, tf.float32)\n",
    "    \n",
    "    mask_p1Bigger = tf.expand_dims(tf.cast(p2_IOU < p1_IOU, tf.float32),-1)\n",
    "    mask_p2Bigger = tf.expand_dims(tf.cast(p1_IOU <= p2_IOU, tf.float32),-1)\n",
    "\n",
    "    # Getting the responsible bounding box for loss calculation. Output is of shape [...,5]\n",
    "    # And the first element is the confidence score of that box.\n",
    "    respBox = maskObj*(mask_p1Bigger * predBox1 + mask_p2Bigger * predBox2)\n",
    "\n",
    "    # Calculating the losses\n",
    "    # 1. Classification loss\n",
    "    classificationLoss =  tf.math.reduce_sum(tf.math.square(maskObj * tf.subtract(targetClass, predClass)))\n",
    "\n",
    "    # 2. Confidence loss\n",
    "    # Bear in mind, for the boxes with no objects, we account for the confidence loss as well. \n",
    "    # To penalize the network for high confidence scores of the cells containing no objects. The \n",
    "    # cells that have no objects, have a confidence score of 0 in the target ground truth matrix.\n",
    "    # Thus, the loss is calculated as follows: SUM_All_Cells_No_OBJ((C1-0)^2 + (C2-0)^2)\n",
    "    confidenceLossObj = tf.math.reduce_sum(tf.math.square(maskObj * tf.subtract(targetConf, tf.expand_dims(respBox[...,0],-1))))\n",
    "    confidenceLossNoObj =  lambdaNoObj * tf.reduce_sum(maskNoObj * tf.reduce_sum(tf.square(predConf), axis = -1, keepdims = True))\n",
    "    \n",
    "    # 3. Localization loss\n",
    "    # Bear in mind that respBox is of the shape (...,5) and targetCoords dimension is (...,4) \n",
    "    xyLoss = (tf.reduce_sum(tf.square(tf.subtract(respBox[...,1:3], targetCoords[...,0:2])),-1,True))\n",
    "    whLoss = (tf.reduce_sum(tf.square(tf.subtract(tf.sqrt(respBox[...,1:3]), tf.sqrt(targetCoords[...,0:2]))),-1,True))\n",
    "    localizationLoss = lambdaCoord * (xyLoss + whLoss) \n",
    "\n",
    "    # Sum all the tree types of the errors\n",
    "    return classificationLoss + confidenceLossNoObj + confidenceLossObj + localizationLoss\n",
    "\n",
    "\n",
    "# # Define a simple model using the custom reshaper layer to test it\n",
    "# input = tf.keras.layers.Input(shape=(539,))\n",
    "# x = YOLOv1_LastLayer_Reshape((7,7,11))(input)\n",
    "# model = tf.keras.Model(inputs = input, outputs = x, name = \"dummy\")\n",
    "# model.compile(optimizer='adam',  loss=testLoss, metrics=['accuracy'])\n",
    "\n",
    "# xTest = np.random.randint(10, size = (1,539))\n",
    "# pred = model.predict(xTest)\n",
    "# # model.evaluate(xTest,np.expand_dims(yTruth, 0),)\n",
    "# model.fit(xTest, np.expand_dims(yTruth, 0), epochs = 1)\n",
    "# # metrics = model.evaluate(xTest)\n",
    "# # print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv1 structure\n",
    "YOLOv1_inputShape = (448,448,3) # Shape of the input image \n",
    "classNo = 1 # Number of classes we are trying to detect\n",
    "input = tf.keras.layers.Input(shape=YOLOv1_inputShape)\n",
    "leakyReLu = tf.keras.layers.LeakyReLU(alpha = .1)\n",
    "\n",
    "\n",
    "# The backbone, Acts ads a feature extractor\n",
    "# L1\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size=7, strides = 2, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(input)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L2\n",
    "x = tf.keras.layers.Conv2D(filters = 192, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L3\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L4\n",
    "for _ in range(4):\n",
    "    x = tf.keras.layers.Conv2D(filters = 256, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "    x = tf.keras.layers.Conv2D(filters = 512, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L5\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 2, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "\n",
    "# L6\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "\n",
    "# Neck\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(4096)(x)\n",
    "x = tf.keras.layers.Dense(7*7*(5*2+classNo), activation=\"sigmoid\")(x)\n",
    "x = tf.keras.layers.Dropout(.5)(x) # Dropout layer for avoiding overfitting\n",
    "x = YOLOv1_LastLayer_Reshape((7,7,5*2+classNo))(x)\n",
    "model = tf.keras.Model(inputs = input, outputs = x, name = \"YOLOv1\")\n",
    "\n",
    "model.compile(loss = testLoss ,optimizer = 'adam')\n",
    "# # Print the architecture\n",
    "# for layer in model.layers:\n",
    "#     print(layer.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-20 19:32:03.358855: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2024-07-20 19:32:03.609875: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-20 19:32:03.839585: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-20 19:32:04.014392: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-20 19:32:04.014463: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-20 19:32:04.079831: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-20 19:32:04.152267: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-20 19:32:04.152306: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-20 19:32:04.196107: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-20 19:32:04.247062: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-20 19:32:04.247101: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-20 19:32:04.265061: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7ee4b2b90ed0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-20 19:32:04.265084: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-07-20 19:32:04.268786: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-20 19:32:04.377095: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 290/1026 [=======>......................] - ETA: 1:35 - loss: 14.2521"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m dfTrain \u001b[38;5;241m=\u001b[39m annotationsToDataframe(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/labels/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m trainingBatchGenerator \u001b[38;5;241m=\u001b[39m dataGenerator_YOLOv1(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/images/train\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m448\u001b[39m,\u001b[38;5;241m448\u001b[39m), dfTrain, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainingBatchGenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdfTrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m135\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m          \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 4\n",
    "\n",
    "dfTrain = annotationsToDataframe(f\"../data/labels/train\", \"txt\")\n",
    "trainingBatchGenerator = dataGenerator_YOLOv1(f\"../data/images/train\", 1, (448,448), dfTrain, 1, True)\n",
    "print(int(dfTrain.shape[0] // batch_size))\n",
    "\n",
    "model.fit(x=trainingBatchGenerator,\n",
    "          steps_per_epoch = int(dfTrain.shape[0] // batch_size),\n",
    "          epochs = 135,\n",
    "          verbose = 1,\n",
    "          workers= 4,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
