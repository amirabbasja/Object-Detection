{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 14:25:31.720838: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 14:25:32.606439: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 14:25:33.682346: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 14:25:33.701998: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 14:25:33.702170: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import keras.backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import sys, os\n",
    "from tensorflow.python.keras.regularizers import l2\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "here = os.path.dirname(\".\")\n",
    "sys.path.append(os.path.join(here, '..'))\n",
    "\n",
    "from dataHandler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv1_LastLayer_Reshape(tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Defines a costume layer for reshaping the last layer to YOLOv1 compatible layer.\n",
    "    Note, No build function is needed.\n",
    "    \"\"\"\n",
    "    def __init__(self, targetShape):\n",
    "        \"\"\"\n",
    "        Initializes the layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.targetShape = tuple(targetShape)\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Helps in serializing the layer data\n",
    "        \"\"\"\n",
    "        config = super().get_config()\n",
    "        config.update({\"target_shape\": self.targetShape})\n",
    "        return config\n",
    "\n",
    "    def call(self, layerInput):\n",
    "        \"\"\"\n",
    "        Forward computations. We take the first Sx * Sy * C indexes of each the input \n",
    "        vector to resemble the class probabilities of each grid cell. The rest of the \n",
    "        Sx * Sy * B indexes resemble the confidence scores of each grid cell And the \n",
    "        rest resemble the bounding box parameters <boxCenterX, boxCenterY, width, height>  \n",
    "\n",
    "        Args:\n",
    "            layerInput: tensor: The output from a dense (fully connected) layer.\n",
    "        \"\"\"\n",
    "        \n",
    "        Sx, Sy = self.targetShape[0], self.targetShape[1] # Number of parts that each axis is divided to\n",
    "        C = 1 # Number of classes\n",
    "        B = 2 # Number of predicted bounding boxes per grid cell\n",
    "\n",
    "\n",
    "        # Get the batch size\n",
    "        batchSize = tf.keras.backend.shape(layerInput)[0]\n",
    "\n",
    "        # Class probabilities\n",
    "        classProbs = tf.keras.backend.reshape(layerInput[:,:Sx*Sy*C], (batchSize,) + (Sx,Sy,C))\n",
    "        classProbs = tf.keras.backend.softmax(classProbs) # Run a softmax to choose the right class with highest prob\n",
    "\n",
    "        # Confidence scores\n",
    "        confScores = tf.keras.backend.reshape(layerInput[:,Sx*Sy*C:Sx*Sy*(C+B)], (batchSize,) + (Sx,Sy,B))\n",
    "        confScores = tf.keras.backend.sigmoid(confScores) # Confidence scores should be between 0 and 1\n",
    "\n",
    "        # Bounding boxes\n",
    "        bBox = tf.keras.backend.reshape(layerInput[:,Sx*Sy*(C+B):], (batchSize,) + (Sx,Sy,B*4))\n",
    "        bBox = tf.keras.backend.sigmoid(bBox) # All of the bounding box parameters are relative (Between 0 and 1)\n",
    "\n",
    "\n",
    "        return tf.keras.backend.concatenate([classProbs, confScores, bBox])\n",
    "\n",
    "# # # Define a simple model using the custom reshaper layer to test it\n",
    "# # input = tf.keras.layers.Input(shape=(539,))\n",
    "# # x = YOLOv1_LastLayer_Reshape((7,7,11))(input)\n",
    "# # model = tf.keras.Model(inputs = input, outputs = x, name = \"dummy\")\n",
    "# # model.compile(optimizer='adam',  loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# # xTest = np.random.randint(10, size = (1,539))\n",
    "# # pred = model.predict(xTest)\n",
    "# # print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 14:25:33.730981: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 14:25:33.731180: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 14:25:33.731287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 14:25:33.795622: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 14:25:33.795815: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 14:25:33.795955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-23 14:25:33.796089: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4807 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1660 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "def iouUtils(boxParams, gridRatio = tf.constant(7, tf.float32)):\n",
    "    \"\"\"\n",
    "    Given bounding box centers and its width and height, calculates top-left and bottom-right coordinates of the box.\n",
    "    Note that calculations in this function are done with teh assumption of w and h being a float number, between 0 and 1\n",
    "    with respect to the entire image's size. However, x and y of the bounding box's center are assumed to be a float \n",
    "    between 0 and 1, with respect to the upper-left point of the grid cell.\n",
    "\n",
    "    Args:\n",
    "        boxParams: tf.Tensor: A tensor with following information (Box center X, Box center Y, Box width, Box height) for all\n",
    "            boxes in a tensor.\n",
    "        gridRatio: int: The number of evenly distributed grid cells in each image axis. Use 7 for YOLOv1.\n",
    "    \n",
    "    Returns:\n",
    "        Two tensors, one indicating top-left pint of the bBox and, the other one denoting bottom-right edge.\n",
    "    \"\"\"\n",
    "    boxXY = boxParams[...,0:2]\n",
    "    halfWH = tf.divide(boxParams[...,2:], tf.constant([2.]))\n",
    "\n",
    "    # Top-left (X, Y) and bottom-right (X, Y)\n",
    "    return tf.subtract(boxXY, halfWH * gridRatio), tf.add(boxXY, halfWH * gridRatio)\n",
    "\n",
    "def calcIOU(predict_topLeft, predict_bottomRight, truth_topLeft, truth_bottomRight):\n",
    "    \"\"\"\n",
    "    Calculates intersection over union for two bounding boxes.\n",
    "\n",
    "    Args:\n",
    "        predict_topLeft, predict_bottomRight: tf.Tensor: Top-left and bottom-right coordinates of the predicted box, acquired \n",
    "            by iouUtils.\n",
    "        truth_topLeft, truth_bottomRight: tf.Tensor: Top-left and bottom-right coordinates of the ground truth box, acquired \n",
    "            by iouUtils.\n",
    "    \n",
    "    Returns:\n",
    "        Intersection over union of two boxes\n",
    "    \"\"\"\n",
    "\n",
    "    intersectEdgeLeft = tf.maximum(predict_topLeft, truth_topLeft)\n",
    "    intersectEdgeRight = tf.minimum(predict_bottomRight, truth_bottomRight)\n",
    "    \n",
    "    intersectWH = tf.abs(tf.subtract(intersectEdgeLeft, intersectEdgeRight))\n",
    "    intersectArea = tf.reduce_prod(intersectWH, axis = -1)\n",
    "\n",
    "    # Get area of predicted and ground truth bounding boxes\n",
    "    predArea = tf.reduce_prod(tf.abs(tf.subtract(predict_topLeft, predict_bottomRight)), axis = -1)\n",
    "    truthArea = tf.reduce_prod(tf.abs(tf.subtract(truth_topLeft, truth_bottomRight)), axis = -1)\n",
    "\n",
    "    \n",
    "    # Return IOU\n",
    "    return tf.divide(intersectArea, predArea + truthArea - intersectArea)\n",
    "\n",
    "# #  Testing IOU code\n",
    "# predict = tf.random.uniform((3,4))\n",
    "# truth = tf.random.uniform((3,4))\n",
    "# p1, p2 = iouUtils(predict)\n",
    "# t1, t2 = iouUtils(truth)\n",
    "# print(calcIOU(p1, p2, t1, t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get test  ground truth vector\n",
    "df = generateGroundTruth_YOLOv1(\"../data/labels/train\", \"txt\", (7,7,1,1))\n",
    "yTruth = df.at[\"04c8acd4a5be79bc\", \"vector\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv1 Loss\n",
    "class YOLOv1_Loss(tf.keras.losses.Loss):\n",
    "    \"\"\"\n",
    "    Defines the custom loss function that is used for YOLOv1 network.\n",
    "    The loss is calculated in 3 parts:\n",
    "    1. Localization Loss\n",
    "    2. Confidence Loss\n",
    "    3. Classification Loss\n",
    "\n",
    "    Note: In this method's documentation, \"ground truth\" and \"target\" are used interchangeably \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, Sx = 7, Sy = 7, B_target = 1, B_pred = 2, C = 1):\n",
    "        \"\"\"\n",
    "        Initializes the loss function. \n",
    "\n",
    "        Args:\n",
    "            Sx: int: Number of grid cells on x axis\n",
    "            Sy: int: Number of grid cells on y axis \n",
    "            B_target: int: Number of bounding boxes in the ground truth data\n",
    "            B_pred: int: Number of bounding boxes in prediction\n",
    "            C: int: Number of the classes\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Define YOLOv1 parameters\n",
    "        self.Sx = Sx\n",
    "        self.Sy = Sy\n",
    "        self.B_target = B_target # Ground truth grid cells only have one bounding box \n",
    "        self.B_pred = B_pred\n",
    "        self.C = C\n",
    "\n",
    "    def call(self, yTrue, yPred):\n",
    "\n",
    "        return 1\n",
    "        \n",
    "def testLoss(yTrue, yPred):\n",
    "    \"\"\"\n",
    "    Runs in the even of loss function calculations\n",
    "    \n",
    "    Args:\n",
    "        yTrue, yPred: tf.Tensor: The ground truth value and the predicted value, respectively\n",
    "\n",
    "    Returns:\n",
    "        The calculated loss.\n",
    "    \"\"\"\n",
    "    lambdaNoObj = tf.constant(.5)\n",
    "    lambdaCoord = tf.constant(5.)\n",
    "\n",
    "    # Split the predictions and ground truth vectors to coordinates, confidence and class matrices\n",
    "    # 1. Ground truth \n",
    "    idx1, idx2 = 1, 1 + 1\n",
    "    targetClass = yTrue[...,:idx1]\n",
    "    targetConf = yTrue[...,idx1:idx2]\n",
    "    targetCoords = yTrue[...,idx2:]\n",
    "\n",
    "    # 2. Prediction\n",
    "    idx1, idx2 = 1, 1 + 2\n",
    "    predClass = yPred[...,:idx1]\n",
    "    predConf = yPred[...,idx1:idx2]\n",
    "    predCoords = yPred[...,idx2:]\n",
    "\n",
    "    # Get the best bounding boxes by calculating the IOUs\n",
    "    # Note: To to do this process for the confidence scores as well, we concat each box's confidence\n",
    "    # score to its bounding box coordinates and analyze them as a whole.\n",
    "    predBox1 = tf.concat([tf.expand_dims(predConf[...,0],-1),predCoords[...,:4]], axis = -1)\n",
    "    predBox2 = tf.concat([tf.expand_dims(predConf[...,1],-1),predCoords[...,4:]], axis = -1)\n",
    "\n",
    "    # Get the corners of bounding boxes to calculate IOUs\n",
    "    # Note, iouUtils is not coded to accept confidence scores. So we only pass the coordinates into \n",
    "    # it. \n",
    "    p1_left, p1_right = iouUtils(predBox1[...,1:]) \n",
    "    p2_left, p2_right = iouUtils(predBox2[...,1:])\n",
    "    t_left, t_right = iouUtils(targetCoords) \n",
    "\n",
    "    # Calculate IOUs for first and second predicted bounding box\n",
    "    p1_IOU = calcIOU(p1_left, p1_right, t_left, t_right)\n",
    "    p2_IOU = calcIOU(p2_left, p2_right, t_left, t_right)\n",
    "\n",
    "    # Get the cells that have objects\n",
    "    maskObj = tf.cast(0 < targetConf, tf.float32)\n",
    "    maskNoObj = tf.cast(0 == targetConf, tf.float32)\n",
    "    \n",
    "    mask_p1Bigger = tf.expand_dims(tf.cast(p2_IOU < p1_IOU, tf.float32),-1)\n",
    "    mask_p2Bigger = tf.expand_dims(tf.cast(p1_IOU <= p2_IOU, tf.float32),-1)\n",
    "\n",
    "    # Getting the responsible bounding box for loss calculation. Output is of shape [...,5]\n",
    "    # And the first element is the confidence score of that box.\n",
    "    respBox = maskObj*(mask_p1Bigger * predBox1 + mask_p2Bigger * predBox2)\n",
    "\n",
    "    # Calculating the losses\n",
    "    # 1. Classification loss\n",
    "    classificationLoss =  tf.math.reduce_sum(tf.math.square(maskObj * tf.subtract(targetClass, predClass)))\n",
    "\n",
    "    # 2. Confidence loss\n",
    "    # Bear in mind, for the boxes with no objects, we account for the confidence loss as well. \n",
    "    # To penalize the network for high confidence scores of the cells containing no objects. The \n",
    "    # cells that have no objects, have a confidence score of 0 in the target ground truth matrix.\n",
    "    # Thus, the loss is calculated as follows: SUM_All_Cells_No_OBJ((C1-0)^2 + (C2-0)^2)\n",
    "    confidenceLossObj = tf.math.reduce_sum(tf.math.square(maskObj * tf.subtract(targetConf, tf.expand_dims(respBox[...,0],-1))))\n",
    "    confidenceLossNoObj =  lambdaNoObj * tf.reduce_sum(maskNoObj * tf.reduce_sum(tf.square(predConf), axis = -1, keepdims = True))\n",
    "    \n",
    "    # 3. Localization loss\n",
    "    # Bear in mind that respBox is of the shape (...,5) and targetCoords dimension is (...,4) \n",
    "    xyLoss = (tf.reduce_sum(tf.square(tf.subtract(respBox[...,1:3], targetCoords[...,0:2])),-1,True))\n",
    "    whLoss = (tf.reduce_sum(tf.square(tf.subtract(tf.sqrt(respBox[...,1:3]), tf.sqrt(targetCoords[...,0:2]))),-1,True))\n",
    "    localizationLoss = lambdaCoord * (xyLoss + whLoss) \n",
    "\n",
    "    # Sum all the tree types of the errors\n",
    "    return classificationLoss + confidenceLossNoObj + confidenceLossObj + localizationLoss\n",
    "\n",
    "\n",
    "# # Define a simple model using the custom reshaper layer to test it\n",
    "# input = tf.keras.layers.Input(shape=(539,))\n",
    "# x = YOLOv1_LastLayer_Reshape((7,7,11))(input)\n",
    "# model = tf.keras.Model(inputs = input, outputs = x, name = \"dummy\")\n",
    "# model.compile(optimizer='adam',  loss=testLoss, metrics=['accuracy'])\n",
    "\n",
    "# xTest = np.random.randint(10, size = (1,539))\n",
    "# pred = model.predict(xTest)\n",
    "# # model.evaluate(xTest,np.expand_dims(yTruth, 0),)\n",
    "# model.fit(xTest, np.expand_dims(yTruth, 0), epochs = 1)\n",
    "# # metrics = model.evaluate(xTest)\n",
    "# # print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLOv1 structure\n",
    "YOLOv1_inputShape = (448,448,3) # Shape of the input image \n",
    "classNo = 1 # Number of classes we are trying to detect\n",
    "input = tf.keras.layers.Input(shape=YOLOv1_inputShape)\n",
    "leakyReLu = tf.keras.layers.LeakyReLU(alpha = .1)\n",
    "\n",
    "\n",
    "# The backbone, Acts ads a feature extractor\n",
    "# L1\n",
    "x = tf.keras.layers.Conv2D(filters = 64, kernel_size=7, strides = 2, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(input)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L2\n",
    "x = tf.keras.layers.Conv2D(filters = 192, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L3\n",
    "x = tf.keras.layers.Conv2D(filters = 128, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 256, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L4\n",
    "for _ in range(4):\n",
    "    x = tf.keras.layers.Conv2D(filters = 256, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "    x = tf.keras.layers.Conv2D(filters = 512, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.MaxPool2D(pool_size=2, strides=2, padding = \"same\")(x)\n",
    "\n",
    "# L5\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 512, kernel_size=1, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 2, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "\n",
    "# L6\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "x = tf.keras.layers.Conv2D(filters = 1024, kernel_size=3, strides = 1, padding = \"same\", activation= leakyReLu, kernel_regularizer=l2(1e-5))(x)\n",
    "\n",
    "# Neck\n",
    "x = tf.keras.layers.Flatten()(x)\n",
    "x = tf.keras.layers.Dense(4096)(x)\n",
    "x = tf.keras.layers.Dense(7*7*(5*2+classNo), activation=\"sigmoid\")(x)\n",
    "x = tf.keras.layers.Dropout(.5)(x) # Dropout layer for avoiding overfitting\n",
    "x = YOLOv1_LastLayer_Reshape((7,7,5*2+classNo))(x)\n",
    "model = tf.keras.Model(inputs = input, outputs = x, name = \"YOLOv1\")\n",
    "\n",
    "model.compile(loss = testLoss ,optimizer = 'adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrScheduler(epoch, schedule, currentLR):\n",
    "    \"\"\"\n",
    "    Returns a learning rate value with respect to epoch number.\n",
    "\n",
    "    Args: \n",
    "        epoch: int: the current epoch number.\n",
    "        schedule: list: A list of tuples of epoch number and its respective learning rate value. \n",
    "            If the epoch number of the fitting process doesn't reach the specified epoch number,\n",
    "            the learning rate will remail unchanged. The entries have to be in order of epoch \n",
    "            numbers.\n",
    "        currentLR: float: The learning rate of the model before starting the most recent epoch.\n",
    "\n",
    "    Returns: float: learning rate.\n",
    "    \"\"\"\n",
    "    \n",
    "    newLR = currentLR\n",
    "\n",
    "    for entry in schedule:\n",
    "        if entry[0] == epoch:\n",
    "            newLR = float(entry[1])\n",
    "    \n",
    "    return newLR\n",
    "\n",
    "class customLearningRate(keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    Sets the learning rate of the fitting process with respect to the epoch number.\n",
    "\n",
    "    Args:\n",
    "        schedule: method: Using the epoch number, returns the suitable learning rate\n",
    "        LR_schedule: list: A list of tuples of epoch number and its respective learning rate value. \n",
    "            If the epoch number of the fitting process doesn't reach the specified epoch number,\n",
    "            the learning rate will remail unchanged. The entries have to be in order of epoch \n",
    "            numbers.\n",
    "    \"\"\"\n",
    "    def __init__(self, scheduleFCN, LR_schedule):\n",
    "        \"\"\"\n",
    "        Initialized the class\n",
    "\n",
    "        Args: \n",
    "            scheduleFCN: method: A method that returns new learning rate\n",
    "            LR_schedule: list: \n",
    "        \"\"\"\n",
    "        super(customLearningRate, self).__init__()\n",
    "        self.LR_schedule = LR_schedule\n",
    "        self.scheduleFCN = scheduleFCN\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        \"\"\"\n",
    "        Runs on the epoch start.\n",
    "\n",
    "        Args:\n",
    "            epoch: int: The current epoch number.\n",
    "        \"\"\"\n",
    "\n",
    "        # # Check to see of the model has defined a learning rate\n",
    "        # if hasattr(self.model.optimizer, \"lr\"):\n",
    "        #     raise Exception(\"custom learning rate generator: First define a learning rate for the model.\")\n",
    "        \n",
    "        # Get current learning rate\n",
    "        learningRate = float(tf.keras.backend.get_value(self.model.optimizer.learning_rate))\n",
    "\n",
    "        # Get the new learning rate\n",
    "        newLearningRate = self.scheduleFCN(epoch, self.LR_schedule, learningRate)\n",
    "\n",
    "        # Set the new learning rate as the model's learning rate\n",
    "        tf.keras.backend.set_value(self.model.optimizer.lr, newLearningRate)\n",
    "\n",
    "        # Notify the user\n",
    "        if learningRate != newLearningRate:\n",
    "            tf.print(f\"Updated the learning rate at epoch NO. {epoch}. New learning rate: {newLearningRate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026\n",
      "Updated the learning rate at epoch NO. 0. New learning rate: 0.01\n",
      "Epoch 1/135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 14:25:39.022432: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2024-07-23 14:25:39.281306: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.55GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 14:25:39.508338: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 14:25:39.692839: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 14:25:39.692885: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.29GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 14:25:39.758721: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.15GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 14:25:39.831340: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 14:25:39.831514: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 14:25:39.879279: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 14:25:39.931626: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.30GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 14:25:39.931751: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 4.27GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-23 14:25:39.954620: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x77c30f67e300 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-23 14:25:39.954645: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce GTX 1660 Ti, Compute Capability 7.5\n",
      "2024-07-23 14:25:39.959146: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-23 14:25:40.075923: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   6/1026 [..............................] - ETA: 2:12 - loss: 16.4422WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0380s vs `on_train_batch_end` time: 0.0762s). Check your callbacks.\n",
      "1026/1026 [==============================] - ETA: 0s - loss: 17.8321\n",
      "Epoch 1: val_loss improved from inf to 18.79725, saving model to ./model_data/model_01-18.80.keras\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The following argument(s) are not supported with the native Keras format: ['options']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m testingBatchGenerator \u001b[38;5;241m=\u001b[39m dataGenerator_YOLOv1(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/images/test\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m448\u001b[39m,\u001b[38;5;241m448\u001b[39m), dfTrain, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mint\u001b[39m(dfTrain\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size))\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrainingBatchGenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdfTrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m135\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m          \u001b[49m\u001b[43mworkers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtestingBatchGenerator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m          \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdfTest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m          \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m              \u001b[49m\u001b[43mcustomLearningRate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlrScheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR_schedule\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m              \u001b[49m\u001b[43mchkPoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m          \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/ml/lib/python3.11/site-packages/keras/src/saving/saving_api.py:142\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 142\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    143\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith the native Keras format: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m         )\n\u001b[1;32m    146\u001b[0m     saving_lib\u001b[38;5;241m.\u001b[39msave_model(model, filepath)\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;66;03m# Legacy case\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The following argument(s) are not supported with the native Keras format: ['options']"
     ]
    }
   ],
   "source": [
    "# See if the directory to save the checkpoints exists\n",
    "if not os.path.isdir(f\"{os.getcwd()}/model_data\"):\n",
    "    os.mkdir(f\"{os.getcwd()}/model_data\")\n",
    "\n",
    "# Instantiate the checkpoint object\n",
    "chkPoint = ModelCheckpoint(filepath='./model_data/model_{epoch:02d}-{val_loss:.2f}.keras',\n",
    "                                      save_best_only=True,\n",
    "                                      monitor='val_loss',\n",
    "                                      mode='min',\n",
    "                                      verbose=1)\n",
    "\n",
    "batch_size = 4\n",
    "LR_schedule = [\n",
    "    (0, 0.01),\n",
    "    (75, 0.001),\n",
    "    (105, 0.0001),\n",
    "]\n",
    "\n",
    "dfTrain = annotationsToDataframe(f\"../data/labels/train\", \"txt\")\n",
    "trainingBatchGenerator = dataGenerator_YOLOv1(f\"../data/images/train\", 1, (448,448), dfTrain, 1, True)\n",
    "\n",
    "dfTest = annotationsToDataframe(f\"../data/labels/test\", \"txt\")\n",
    "testingBatchGenerator = dataGenerator_YOLOv1(f\"../data/images/test\", 1, (448,448), dfTrain, 1, True)\n",
    "print(int(dfTrain.shape[0] // batch_size))\n",
    "\n",
    "model.fit(x=trainingBatchGenerator,\n",
    "          steps_per_epoch = int(dfTrain.shape[0] // batch_size),\n",
    "          epochs = 135,\n",
    "          verbose = 1,\n",
    "          workers = 4,\n",
    "          validation_data = testingBatchGenerator,\n",
    "          validation_steps = int(len(dfTest) // batch_size),\n",
    "          callbacks = [\n",
    "              customLearningRate(lrScheduler, LR_schedule),\n",
    "              chkPoint,\n",
    "          ]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
